{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Iterative methods for solving linear systems\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recall the prototypal PDE problem introduced in the Lecture 08:\n",
    "$$\n",
    "-u_{xx}(x) = f(x)\\quad\\mathrm{ in }\\ \\Omega = (0, 1)\n",
    "$$\n",
    "$$\n",
    "u(x) = 0, \\quad\\mathrm{ on }\\ \\partial\\Omega = \\{0, 1\\}\n",
    "$$\n",
    "\n",
    "For the numerical discretization of the problem, we consider a **Finite Difference (FD) Approximation**. Let $n$ be an integer, a consider a uniform subdivision of the interval $(0,1)$ using $n$ equispaced points, denoted by $\\{x_i\\}_{i=0}^n$ . Moreover, let $u_i$ be the FD approximation of $u(x_i)$, and similarly $f_i \\approx f(x_i)$.\n",
    "\n",
    "The linear system that we need to solve is\n",
    "$$\n",
    "u_i = 0 \\qquad\\qquad\\qquad\\qquad i=0,\n",
    "$$\n",
    "$$\n",
    "\\frac{-u_{i-1} + 2u_i - u_{i+1}}{h^2} = f_i \\qquad\\qquad\\qquad i=1, \\ldots, n-1,\\qquad\\qquad\\qquad(P)\n",
    "$$\n",
    "$$\n",
    "u_i = 0 \\qquad\\qquad\\qquad\\qquad i=n.\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from numpy import *\n",
    "from matplotlib.pyplot import *\n",
    "\n",
    "n = 330\n",
    "h = 1./(n-1)\n",
    "\n",
    "x=linspace(0,1,n)\n",
    "\n",
    "a = -ones((n-1,)) # Offdiagonal entries\n",
    "b = 2*ones((n,)) # Diagonal entries\n",
    "A = (diag(a, -1) + diag(b, 0) + diag(a, +1))\n",
    "A /= h**2\n",
    "f = x*(1.-x)\n",
    "\n",
    "# Change first row of the matrix A\n",
    "A[0,:] = 0\n",
    "A[:,0] = 0\n",
    "A[0,0] = 1\n",
    "f[0] = 0\n",
    "\n",
    "# Change last row of the matrix A\n",
    "A[-1,:] = 0\n",
    "A[:,-1] = 0\n",
    "A[-1,-1] = 1\n",
    "f[-1] = 0\n",
    "\n",
    "# Solution by direct method\n",
    "u = linalg.solve(A, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Jacobi\n",
    "\n",
    "$$ \n",
    "x_i^{k+1} = \\frac{1}{A_{ii}} \\times \\left(b_i - \\sum_{j\\neq i} a_{ij}x_j^k\\right)\n",
    "$$\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "exit at iter 4776 for tolerance\n",
      "9.682097967515382e-11\n"
     ]
    }
   ],
   "source": [
    "def jacobi(A, b, x0=np.zeros_like(b), nmax=10000, eps=1e-10):\n",
    "    x = x0.copy()\n",
    "    xl = x.copy()\n",
    "    \n",
    "    if np.linalg.norm(A.dot(x) - b, 2) < eps:\n",
    "        return x\n",
    "\n",
    "    #allocates a second matrix, might be forbidden\n",
    "    #At = A.copy()\n",
    "    #for i in range(At.shape[0]):\n",
    "    #    At[i, i] = 0\n",
    "    #Ad = np.diag(A)\n",
    "    \n",
    "    for it in range(nmax):\n",
    "        #x = (b - At.dot(x)) / Ad\n",
    "        #no allocation\n",
    "        for i in range(n):\n",
    "            x[i] = (b[i] - (A[i, :i].dot(xl[:i]) + A[i, i+1:].dot(xl[i+1:]))) / A[i, i]\n",
    "        \n",
    "        if np.linalg.norm(A.dot(x) - b, 2) < eps: #diff ~1e-10\n",
    "            print(f\"exit at iter {it} for tolerance\")\n",
    "            break\n",
    "            \n",
    "        xl[:] = x[:]\n",
    "        \n",
    "    return x\n",
    "\n",
    "sol_jacobi = jacobi(A, f)\n",
    "print(linalg.norm(sol_jacobi - u)/linalg.norm(u))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gauss-Seidel\n",
    "\n",
    "$$ \n",
    "x_i^{k+1} = \\frac{1}{A_{ii}} \\times \\left(b_i - \\sum_{j=0}^{i-1} a_{ij}x_j^{k+1} - \\sum_{j=i+1}^{N} a_{ij}x_j^k\\right)\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "exit at iter 2389 for tolerance\n",
      "9.577286625150912e-11\n"
     ]
    }
   ],
   "source": [
    "def gauss_seidel(A,b, x0=np.zeros_like(b),nmax=10000, eps=1e-10):\n",
    "    x = x0.copy()\n",
    "    xl = x.copy()\n",
    "    \n",
    "    if np.linalg.norm(A.dot(x) - b, 2) < eps:\n",
    "        return x\n",
    "\n",
    "    P = np.tril(A)\n",
    "    Bgs = np.linalg.inv(P).dot(np.diag(np.diag(A))-np.triu(A))#.dot(P - A)\n",
    "    g = np.linalg.solve(P, b)\n",
    "    n = b.shape[0]\n",
    "    \n",
    "    for it in range(nmax):\n",
    "        #for i in range(n):\n",
    "        #    x[i] = (b[i] - (A[i, :i].dot(x[:i]) + A[i, i+1:].dot(xl[i+1:]))) / A[i, i]\n",
    "        x = Bgs.dot(x) + g\n",
    "        \n",
    "        if np.linalg.norm(A.dot(x) - b, 2) < eps: #diff ~1e-10\n",
    "        #if np.linalg.norm(x-xl) < eps: #diff ~1e-8\n",
    "        #if np.max(np.abs(x-xl)) < eps: #diff ~1e-7\n",
    "            print(f\"exit at iter {it} for tolerance\")\n",
    "            break\n",
    "            \n",
    "        xl[:] = x[:]\n",
    "    \n",
    "    return x\n",
    "\n",
    "sol_gauss_seidel = gauss_seidel(A, f)\n",
    "print(linalg.norm(sol_gauss_seidel - u)/linalg.norm(u))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "   ## Gradient method\n",
    "   $$\n",
    "   {\\bf r}^k = {\\bf b} - A {\\bf x}^k\n",
    "   $$\n",
    "   \n",
    "   $$\n",
    "   \\alpha^k = \\frac{{\\bf r}^{k^{T}} {\\bf r}^k}{{\\bf r}^{k^{T}} A{\\bf r}^k}\n",
    "   $$\n",
    "   \n",
    "   $$\n",
    "   {\\bf x}^{k+1} = {\\bf x}^k + \\alpha^k {\\bf r}^k\n",
    "   $$\n",
    "   \n",
    "   ### Preconditioned gradient method\n",
    "   $$\n",
    "   P{\\bf z}^k =  {\\bf r}^k\n",
    "   $$\n",
    "   \n",
    "   $$\n",
    "   \\alpha^k = \\frac{{\\bf z}^{k^{T}} {\\bf r}^k}{{\\bf z}^{k^{T}} A{\\bf z}^k}\n",
    "   $$\n",
    " \n",
    "   $$\n",
    "   {\\bf x}^{k+1} = {\\bf x}^k + \\alpha^k {\\bf z}^k\n",
    "   $$ \n",
    "   \n",
    "   $$\n",
    "   {\\bf r}^{k+1} = {\\bf r}^k  - \\alpha^k A{\\bf z}^k\n",
    "   $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "exit at iter 3908 for tolerance\n",
      "7.0953071470574e-11\n",
      "exit at iter 0 for tolerance\n",
      "4.619189381061087e-15\n"
     ]
    }
   ],
   "source": [
    "def gradient(A, b, P, x0=np.zeros_like(b), nmax=8000, eps=1e-10):\n",
    "    x = x0.copy()\n",
    "    r = b - A.dot(x)\n",
    "    #print(f\"initial r {r}\")\n",
    "    \n",
    "    if np.linalg.norm(r, 2) < eps:\n",
    "        return x\n",
    "    \n",
    "    Pinv = np.linalg.inv(P)\n",
    "    \n",
    "    for it in range(nmax):\n",
    "        z = Pinv.dot(r)\n",
    "        #z = np.linalg.solve(P, r)\n",
    "        Az = A.dot(z)\n",
    "        a = z.dot(r) / z.dot(Az)\n",
    "        x += a * z\n",
    "        r -= a * Az\n",
    "        \n",
    "        if np.linalg.norm(r, 2) < eps: #diff ~1e-11\n",
    "        #if np.linalg.norm(a * z) < eps: #diff ~1e-7\n",
    "            print(f\"exit at iter {it} for tolerance\")\n",
    "            break\n",
    "    \n",
    "    return x\n",
    "    \n",
    "sol_gradient = gradient(A, f, identity(len(A)))\n",
    "print(linalg.norm(sol_gradient - u)/linalg.norm(u))\n",
    "sol_preconditioned_gradient = gradient(A, f, A)\n",
    "print(linalg.norm(sol_preconditioned_gradient - u)/linalg.norm(u))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conjugate gradient\n",
    "   \n",
    "   $$\n",
    "   \\alpha^k = \\frac{{\\bf p}^{k^{T}} {\\bf r}^k}{{\\bf p}^{k^{T}} A{\\bf p}^k}\n",
    "   $$\n",
    "   \n",
    "      \n",
    "   $$\n",
    "   {\\bf x}^{k+1} = {\\bf x}^k + \\alpha^k {\\bf p}^k\n",
    "   $$\n",
    "   \n",
    "   $$\n",
    "   {\\bf r}^{k+1} = {\\bf r}^k - \\alpha^kA {\\bf p}^k\n",
    "   $$\n",
    "\n",
    "   $$\n",
    "   \\beta^k = \\frac{(A{\\bf p}^{k})^{T}{\\bf r}^{k+1}}{(A{\\bf p}^{k})^{T}  {\\bf p}^k}\n",
    "   $$\n",
    "   \n",
    "   $$\n",
    "   {\\bf p}^{k+1} = {\\bf r}^{k+1} - \\beta^k{\\bf p}^k\n",
    "   $$\n",
    "\n",
    "   \n",
    "   ### Preconditioned conjugate gradient\n",
    "   \n",
    "   \n",
    "   $$\n",
    "   \\alpha^k = \\frac{{\\bf p}^{k^{T}} {\\bf r}^k}{(A{\\bf p}^{k})^{T}{\\bf p}^k}\n",
    "   $$\n",
    "   \n",
    "      \n",
    "   $$\n",
    "   {\\bf x}^{k+1} = {\\bf x}^k + \\alpha^k {\\bf p}^k\n",
    "   $$\n",
    "   \n",
    "   $$\n",
    "   {\\bf r}^{k+1} = {\\bf r}^k - \\alpha^kA {\\bf p}^k\n",
    "   $$\n",
    "\n",
    "$$\n",
    "P{\\bf z}^{k+1} = {\\bf r}^{k+1}\n",
    "$$\n",
    "\n",
    "   $$\n",
    "   \\beta^k = \\frac{(A{\\bf p}^{k})^{T}{\\bf z}^{k+1}}{{\\bf p}^{k^T}A  {\\bf p}^k}\n",
    "   $$\n",
    "   \n",
    "   $$\n",
    "   {\\bf p}^{k+1} = {\\bf z}^{k+1} - \\beta^k{\\bf p}^k\n",
    "   $$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter 0 r*z 1.758e-01 z*p 1.758e-01 p*r 1.758e-01\n",
      "iter 1 r*z 3.803e-01 z*p 3.803e-01 p*r 3.803e-01\n",
      "iter 2 r*z 2.508e-01 z*p 2.508e-01 p*r 2.508e-01\n",
      "iter 3 r*z 1.603e-01 z*p 1.603e-01 p*r 1.603e-01\n",
      "iter 4 r*z 9.880e-02 z*p 9.880e-02 p*r 9.880e-02\n",
      "iter 5 r*z 5.835e-02 z*p 5.835e-02 p*r 5.835e-02\n",
      "iter 6 r*z 3.273e-02 z*p 3.273e-02 p*r 3.273e-02\n",
      "iter 7 r*z 1.725e-02 z*p 1.725e-02 p*r 1.725e-02\n",
      "iter 8 r*z 8.409e-03 z*p 8.409e-03 p*r 8.409e-03\n",
      "iter 9 r*z 3.709e-03 z*p 3.709e-03 p*r 3.709e-03\n",
      "iter 10 r*z 1.432e-03 z*p 1.432e-03 p*r 1.432e-03\n",
      "iter 11 r*z 4.582e-04 z*p 4.582e-04 p*r 4.582e-04\n",
      "iter 12 r*z 1.101e-04 z*p 1.101e-04 p*r 1.101e-04\n",
      "iter 13 r*z 1.602e-05 z*p 1.602e-05 p*r 1.602e-05\n",
      "iter 14 r*z 6.676e-07 z*p 6.676e-07 p*r 6.676e-07\n",
      "iter 15 r*z 7.949e-33 z*p 7.949e-33 p*r 7.949e-33\n",
      "exit at iter 15 for tolerance\n",
      "2.9030318378385336e-15\n"
     ]
    }
   ],
   "source": [
    "def conjugate_gradient(A, b, P, x0=np.zeros_like(b), nmax=len(A), eps=1e-10):\n",
    "    x = x0.copy()\n",
    "    r = b - A.dot(x)\n",
    "    #print(f\"initial r {r}\")\n",
    "    \n",
    "    if np.linalg.norm(r, 2) < eps:\n",
    "        return x\n",
    "    \n",
    "    #p = np.linalg.solve(P, r)\n",
    "    Pinv = np.linalg.inv(P)\n",
    "    p = Pinv.dot(r)\n",
    "    \n",
    "    for it in range(nmax):\n",
    "        Ap = A.dot(p)\n",
    "        a = p.dot(r) / p.dot(Ap)\n",
    "        \n",
    "        x += a * p\n",
    "        r -= a * Ap\n",
    "        z = Pinv.dot(r)\n",
    "        #z = np.linalg.solve(P, r)\n",
    "        \n",
    "        be = Ap.dot(z) / Ap.dot(p)\n",
    "        p = z - be * p\n",
    "            \n",
    "        #print(f\"iter {it} a {a} b {be}\")\n",
    "        #print(f\"iter {it} r*z {r.dot(z):.3e} z*p {z.dot(p):.3e} p*r {p.dot(r):.3e}\")\n",
    "        if np.linalg.norm(r, 2) < eps: #diff ~1e-11\n",
    "        #if np.linalg.norm(a * z) < eps: #diff ~1e-7\n",
    "            print(f\"exit at iter {it} for tolerance\")\n",
    "            break\n",
    "    \n",
    "    return x\n",
    "\n",
    "sol_conjugate_gradient = conjugate_gradient(A, f, identity(len(A)))\n",
    "#sol_conjugate_gradient = conjugate_gradient(A, f, np.diag(np.diag(A)))#no gain over identity\n",
    "#sol_conjugate_gradient = conjugate_gradient(A, f, np.diag(1 / np.diag(A)))#no gain over identity\n",
    "#sol_conjugate_gradient = conjugate_gradient(A, f, np.linalg.inv(A))#worse\n",
    "#sol_conjugate_gradient = conjugate_gradient(A, f, np.tril(A)) #maxes iterations\n",
    "print(linalg.norm(sol_conjugate_gradient - u)/linalg.norm(u))\n",
    "#sol_preconditioned_conjugate_gradient = conjugate_gradient(A, f, A)\n",
    "#print(linalg.norm(sol_preconditioned_conjugate_gradient - u)/linalg.norm(u))"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
